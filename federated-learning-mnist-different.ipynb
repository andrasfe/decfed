{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport random\nimport cv2\nimport os\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import accuracy_score\n\nimport tensorflow as tf\nfrom tensorflow import expand_dims\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Input, Lambda\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.layers import Activation\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras import backend as K","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-31T19:46:20.707333Z","iopub.execute_input":"2022-12-31T19:46:20.707711Z","iopub.status.idle":"2022-12-31T19:46:20.714369Z","shell.execute_reply.started":"2022-12-31T19:46:20.707653Z","shell.execute_reply":"2022-12-31T19:46:20.713502Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"!pip install imutils\nfrom imutils import paths","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:28:50.779385Z","iopub.execute_input":"2022-12-31T16:28:50.779756Z","iopub.status.idle":"2022-12-31T16:29:00.017916Z","shell.execute_reply.started":"2022-12-31T16:28:50.779717Z","shell.execute_reply":"2022-12-31T16:29:00.016916Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting imutils\n  Downloading imutils-0.5.4.tar.gz (17 kB)\nBuilding wheels for collected packages: imutils\n  Building wheel for imutils (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25860 sha256=1fd8fb0d744c3a1d229ef79abc93cee97d1c698e299a492522657e1e1f818844\n  Stored in directory: /root/.cache/pip/wheels/86/d7/0a/4923351ed1cec5d5e24c1eaf8905567b02a0343b24aa873df2\nSuccessfully built imutils\nInstalling collected packages: imutils\nSuccessfully installed imutils-0.5.4\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Todo\n\ncreate subset of clients\n\n- increase comm rounds 300\n- increase hidden units 400\n- increase no of layers\n- no of clients 20","metadata":{}},{"cell_type":"code","source":"debug = 0","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:29:00.021796Z","iopub.execute_input":"2022-12-31T16:29:00.022085Z","iopub.status.idle":"2022-12-31T16:29:00.028781Z","shell.execute_reply.started":"2022-12-31T16:29:00.022054Z","shell.execute_reply":"2022-12-31T16:29:00.027994Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def load(paths, verbose=-1):\n    '''expects images for each class in seperate dir, \n    e.g all digits in 0 class in the directory named 0 '''\n    data = list()\n    labels = list()\n    # loop over the input images\n    for (i, imgpath) in enumerate(paths):\n        # load the image and extract the class labels        \n        im_gray = cv2.imread(imgpath , cv2.IMREAD_GRAYSCALE)\n        image = np.array(im_gray).flatten() # cv2.imread(imgpath) \n        # print(image.shape)\n        label = imgpath.split(os.path.sep)[-2]\n        # scale the image to [0, 1] and add to list\n        data.append(image/255)\n        labels.append(label)\n        # show an update every `verbose` images\n        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n    # return a tuple of the data and labels\n    \n    return data, labels\n\ndef create_clients(image_list, label_list, num_clients=100, initial='clients'):\n    ''' return: a dictionary with keys clients' names and value as \n                data shards - tuple of images and label lists.\n        args: \n            image_list: a list of numpy arrays of training images\n            label_list:a list of binarized labels for each image\n            num_client: number of fedrated members (clients)\n            initials: the clients'name prefix, e.g, clients_1 \n            \n    '''\n\n    #create a list of client names\n    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n\n    #randomize the data\n    data = list(zip(image_list, label_list))\n    random.shuffle(data)  # <- IID\n    \n    # sort data for non-iid\n#     max_y = np.argmax(label_list, axis=-1)\n#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n#     data = [(x,y) for _,y,x in sorted_zip]\n\n    #shard data and place at each client\n    size = len(data)//num_clients\n    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n\n    #number of clients must equal number of shards\n    assert(len(shards) == len(client_names))\n\n    return {client_names[i] : shards[i] for i in range(len(client_names))} \n\n\ndef batch_data(data_shard, bs=32, flip=False):\n    '''Takes in a clients data shard and create a tfds object off it\n    args:\n        shard: a data, label constituting a client's data shard\n        bs:batch size\n    return:\n        tfds object'''\n    #seperate shard into data and labels lists\n    data, label = zip(*data_shard)\n    labels = list(label)\n    \n    if flip == True:\n        random.shuffle(labels)\n        \n    dataset = tf.data.Dataset.from_tensor_slices((list(data), labels))\n    return dataset.shuffle(len(label)).batch(bs)\n\n\ndef weight_scalling_factor(clients_trn_data, client_name):\n    client_names = list(clients_trn_data.keys())\n    #get the bs\n    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n    #first calculate the total training data points across clinets\n    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n    # get the total number of data points held by a client\n    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n    \n    \n    if debug:\n        print('global_count', global_count, 'local_count', local_count, 'bs', bs)\n    \n    return local_count/global_count\n\n\ndef scale_model_weights(weight, scalar):\n    '''function for scaling a models weights'''\n    weight_final = []\n    steps = len(weight)\n    for i in range(steps):\n        weight_final.append(scalar * weight[i])\n    return weight_final\n\n\n\ndef sum_scaled_weights(scaled_weight_list):\n    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n    avg_grad = list()\n    #get the average grad accross all client gradients\n    for grad_list_tuple in zip(*scaled_weight_list):\n        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n        avg_grad.append(layer_mean)\n        \n    return avg_grad\n\n\ndef test_model(X_test, Y_test,  model, comm_round):\n    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n    #logits = model.predict(X_test, batch_size=100)\n    logits = model.predict(X_test)\n    loss = cce(Y_test, logits)\n    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n    return acc, loss\n","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:37:30.855211Z","iopub.execute_input":"2022-12-31T19:37:30.855583Z","iopub.status.idle":"2022-12-31T19:37:30.873388Z","shell.execute_reply.started":"2022-12-31T19:37:30.855547Z","shell.execute_reply":"2022-12-31T19:37:30.872536Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"class SimpleMLP:\n    @staticmethod\n    def build(shape, classes):\n        model = Sequential()\n        model.add(Dense(200, input_shape=(shape,)))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(200))\n        model.add(Activation(\"relu\"))\n        model.add(Dense(classes))\n        model.add(Activation(\"softmax\"))\n        return model\n    \n#     def build(shape, classes):\n#         model = Sequential()\n#         model.add(Input(shape=(shape[0], shape[1], shape[2])))\n#         #model.add(Lambda(lambda x: expand_dims(x, axis=-1)))\n#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n#         model.add(Activation(\"relu\"))\n#         model.add(MaxPooling2D())\n#         model.add(Flatten())\n#         model.add(Dense(32))\n#         model.add(Dense(classes))\n#         model.add(Activation(\"softmax\"))\n#         return model","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:29:00.052608Z","iopub.execute_input":"2022-12-31T16:29:00.053003Z","iopub.status.idle":"2022-12-31T16:29:00.058414Z","shell.execute_reply.started":"2022-12-31T16:29:00.052871Z","shell.execute_reply":"2022-12-31T16:29:00.057500Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#declear path to your mnist data folder\nimg_path = '../input/mnistasjpg/trainingSet/trainingSet' #'../input/cifar10-pngs-in-folders/cifar10/test'  # <-- test dataset #'../input/mnistasjpg/trainingSample/trainingSample' # <-- smaller dataset\n\n#get the path list using the path object\nimage_paths = list(paths.list_images(img_path))\n\n#apply our function\nimage_list, label_list = load(image_paths, verbose=10000)\n\n#binarize the labels\nlb = LabelBinarizer()\nlabel_list = lb.fit_transform(label_list)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-12-31T16:29:00.059992Z","iopub.execute_input":"2022-12-31T16:29:00.060684Z","iopub.status.idle":"2022-12-31T16:35:11.473352Z","shell.execute_reply.started":"2022-12-31T16:29:00.060630Z","shell.execute_reply":"2022-12-31T16:35:11.472432Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[INFO] processed 10000/42000\n[INFO] processed 20000/42000\n[INFO] processed 30000/42000\n[INFO] processed 40000/42000\n","output_type":"stream"}]},{"cell_type":"code","source":"#split data into training and test set\nX_train, X_test, y_train, y_test = train_test_split(image_list, \n                                                    label_list, \n                                                    test_size=0.1, \n                                                    random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:11.474834Z","iopub.execute_input":"2022-12-31T16:35:11.475182Z","iopub.status.idle":"2022-12-31T16:35:11.496293Z","shell.execute_reply.started":"2022-12-31T16:35:11.475140Z","shell.execute_reply":"2022-12-31T16:35:11.495498Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"### IID","metadata":{}},{"cell_type":"code","source":"len(X_train), len(X_test), len(y_train), len(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:11.500023Z","iopub.execute_input":"2022-12-31T16:35:11.500529Z","iopub.status.idle":"2022-12-31T16:35:11.508823Z","shell.execute_reply.started":"2022-12-31T16:35:11.500491Z","shell.execute_reply":"2022-12-31T16:35:11.507773Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(37800, 4200, 37800, 4200)"},"metadata":{}}]},{"cell_type":"code","source":"#create clients\nclients = create_clients(X_train, y_train, num_clients=100, initial='client')","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:11.511001Z","iopub.execute_input":"2022-12-31T16:35:11.511438Z","iopub.status.idle":"2022-12-31T16:35:11.562546Z","shell.execute_reply.started":"2022-12-31T16:35:11.511402Z","shell.execute_reply":"2022-12-31T16:35:11.561628Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# client_names = ['{}_{}'.format('client', i+1) for i in range(100)]\n# s = clients['client_1'][0][1]*0\n# for c in client_names:\n#     sum = clients[c][0][1]\n#     for i in range(1,378):\n#         sum = sum + clients[c][i][1]\n        \n#     s = s + sum/378\n# s","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:11.563835Z","iopub.execute_input":"2022-12-31T16:35:11.564180Z","iopub.status.idle":"2022-12-31T16:35:11.571126Z","shell.execute_reply.started":"2022-12-31T16:35:11.564144Z","shell.execute_reply":"2022-12-31T16:35:11.570318Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#process and batch the training data for each client\nclients_batched = dict()\nfor (client_name, data) in clients.items():\n    clients_batched[client_name] = batch_data(data)\n    \n#process and batch the test set  \ntest_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:11.572226Z","iopub.execute_input":"2022-12-31T16:35:11.572477Z","iopub.status.idle":"2022-12-31T16:35:18.245504Z","shell.execute_reply.started":"2022-12-31T16:35:11.572452Z","shell.execute_reply":"2022-12-31T16:35:18.244655Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"lr = 0.01\ncomms_round = 300\nloss='categorical_crossentropy'\nmetrics = ['accuracy']\noptimizer = SGD(lr=lr, \n                decay=lr / comms_round, \n                momentum=0.9\n               )          ","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:18.246803Z","iopub.execute_input":"2022-12-31T16:35:18.247141Z","iopub.status.idle":"2022-12-31T16:35:18.252095Z","shell.execute_reply.started":"2022-12-31T16:35:18.247103Z","shell.execute_reply":"2022-12-31T16:35:18.251109Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#initialize global model\n\nbuild_shape = 784 #(28, 28, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n\nsmlp_global = SimpleMLP()\nglobal_model = smlp_global.build(build_shape, 10) \nglobal_acc_list = []\nglobal_loss_list = []","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:18.253340Z","iopub.execute_input":"2022-12-31T16:35:18.253903Z","iopub.status.idle":"2022-12-31T16:35:18.631502Z","shell.execute_reply.started":"2022-12-31T16:35:18.253869Z","shell.execute_reply":"2022-12-31T16:35:18.630552Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Non-IID","metadata":{}},{"cell_type":"code","source":"def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n    ''' return: a dictionary with keys clients' names and value as \n                data shards - tuple of images and label lists.\n        args: \n            image_list: a list of numpy arrays of training images\n            label_list:a list of binarized labels for each image\n            num_client: number of fedrated members (clients)\n            initials: the clients'name prefix, e.g, clients_1 \n            \n    '''\n\n    #create a list of client names\n    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n\n    #randomize the data\n    # data = list(zip(image_list, label_list))\n    # random.shuffle(data)  # <- IID\n    \n    # sort data for non-iid\n    max_y = np.argmax(label_list, axis=-1)\n    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n    data = [(x,y) for _,y,x in sorted_zip]\n\n    #shard data and place at each client\n    size = len(data)//num_clients\n    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n\n    #number of clients must equal number of shards\n    assert(len(shards) == len(client_names))\n\n    return {client_names[i] : shards[i] for i in range(len(client_names))} ","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:18.633655Z","iopub.execute_input":"2022-12-31T16:35:18.634246Z","iopub.status.idle":"2022-12-31T16:35:18.642422Z","shell.execute_reply.started":"2022-12-31T16:35:18.634206Z","shell.execute_reply":"2022-12-31T16:35:18.641489Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train), len(X_test), len(y_train), len(y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:18.644339Z","iopub.execute_input":"2022-12-31T16:35:18.645028Z","iopub.status.idle":"2022-12-31T16:35:18.656221Z","shell.execute_reply.started":"2022-12-31T16:35:18.644990Z","shell.execute_reply":"2022-12-31T16:35:18.655190Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(37800, 4200, 37800, 4200)"},"metadata":{}}]},{"cell_type":"code","source":"#create clients\nclients = create_clients(X_train, y_train, num_clients=100, initial='client')","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:38:38.018448Z","iopub.execute_input":"2022-12-31T19:38:38.018808Z","iopub.status.idle":"2022-12-31T19:38:38.090205Z","shell.execute_reply.started":"2022-12-31T19:38:38.018773Z","shell.execute_reply":"2022-12-31T19:38:38.089362Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"#process and batch the training data for each client\nclients_batched = dict()\nflipped = []\nfor (client_name, data) in clients.items():\n    flip = True if random.randint(0,100) < 20 else False\n    if flip:\n        flipped.append(client_name)\n    clients_batched[client_name] = batch_data(data, flip=flip)\n    \nprint('flipped:', len(flipped))\n    \n#process and batch the test set  \ntest_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:41:47.401418Z","iopub.execute_input":"2022-12-31T19:41:47.401756Z","iopub.status.idle":"2022-12-31T19:41:51.555508Z","shell.execute_reply.started":"2022-12-31T19:41:47.401722Z","shell.execute_reply":"2022-12-31T19:41:51.554569Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"flipped: 16\n","output_type":"stream"}]},{"cell_type":"code","source":"lr = 0.01 \ncomms_round = 300\nloss='categorical_crossentropy'\nmetrics = ['accuracy']\noptimizer = SGD(lr=lr, \n                decay=lr / comms_round, \n                momentum=0.9\n               )          ","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:42:12.264124Z","iopub.execute_input":"2022-12-31T19:42:12.264444Z","iopub.status.idle":"2022-12-31T19:42:12.268966Z","shell.execute_reply.started":"2022-12-31T19:42:12.264411Z","shell.execute_reply":"2022-12-31T19:42:12.268024Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"#initialize global model\n\nbuild_shape = 784 #(32, 32, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n\nsmlp_global = SimpleMLP()\nglobal_model = smlp_global.build(build_shape, 10) \nglobal_acc_list = []\nglobal_loss_list = []\n\nglobal_model.save_weights('model.h5')\n\ndef reset_model():\n    global_model.load_weights('model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:42:16.035243Z","iopub.execute_input":"2022-12-31T19:42:16.035579Z","iopub.status.idle":"2022-12-31T19:42:16.082309Z","shell.execute_reply.started":"2022-12-31T19:42:16.035544Z","shell.execute_reply":"2022-12-31T19:42:16.081328Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"def fed_avg(weights):\n    assert(len(weights) > 0)\n    n_layers = len(weights[0])\n\n    avg_weights = list()\n\n    for layer in range(n_layers):\n        layer_weights = np.array([w[layer] for w in weights])\n        mean_layer_weights = np.mean(layer_weights, axis = 0)\n        avg_weights.append(mean_layer_weights)\n\n    return avg_weights\n","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:23.249438Z","iopub.execute_input":"2022-12-31T16:35:23.249789Z","iopub.status.idle":"2022-12-31T16:35:23.255028Z","shell.execute_reply.started":"2022-12-31T16:35:23.249749Z","shell.execute_reply":"2022-12-31T16:35:23.254101Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def score(weights, trainers):\n    R = len(weights)\n    f = R // 3 - 1\n    closest_updates = R - f - 2\n\n    scores = []\n\n    for i in range(len(weights)):\n      dists = []\n\n      for j in range(len(weights)):\n        if i == j:\n          continue\n\n        diff = np.subtract(weights[j],weights[i])\n        l2_norm = np.sqrt(np.sum([np.sum(np.square(w)) for w in diff]))\n        dists.append(l2_norm)\n\n      dists_sorted = np.argsort(dists)[:closest_updates]\n      score = np.array([dists[i] for i in dists_sorted]).sum()\n      scores.append(score)\n    return trainers, scores, weights","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:23.256496Z","iopub.execute_input":"2022-12-31T16:35:23.257023Z","iopub.status.idle":"2022-12-31T16:35:23.265911Z","shell.execute_reply.started":"2022-12-31T16:35:23.256987Z","shell.execute_reply":"2022-12-31T16:35:23.264580Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def local_score(weights, my_weights, other_trainers):\n    R = len(weights)\n    f = R // 3 - 1\n    closest_updates = R - f - 2\n\n    dists = []\n\n    for i in range(len(weights)):\n        diff = np.subtract(weights[i], my_weights)\n        l2_norm = np.sqrt(np.sum([np.sum(np.square(w)) for w in diff]))\n        dists.append(l2_norm)\n\n    dists_sorted = np.argsort(dists)[:closest_updates]\n    return [other_trainers[i] for i in dists_sorted]","metadata":{"execution":{"iopub.status.busy":"2022-12-31T20:05:42.213748Z","iopub.execute_input":"2022-12-31T20:05:42.214090Z","iopub.status.idle":"2022-12-31T20:05:42.220649Z","shell.execute_reply.started":"2022-12-31T20:05:42.214058Z","shell.execute_reply":"2022-12-31T20:05:42.219636Z"},"trusted":true},"execution_count":125,"outputs":[]},{"cell_type":"code","source":"# client/trainer cannot add itself to this list, as SC would reject it\ndef local_preference_calc(comm_round, historical_weight_dict, historical_preference_dict, my_trainer):\n    if comm_round not in historical_weight_dict.keys():\n        return\n    \n    prior_weight_dict =  historical_weight_dict[comm_round]\n    trainers = list(prior_weight_dict.keys())\n    weights = list(prior_weight_dict.values())\n    my_index = trainers.index(my_trainer)\n    my_weights = weights[my_index]\n    trainers.pop(my_index)\n    weights.pop(my_index)\n    \n    historical_preference_dict_round = historical_preference_dict[comm_round]\n    preferred_trainer_list =  local_score(weights, my_weights, trainers)\n    historical_preference_dict_round[my_trainer] = preferred_trainer_list\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-12-31T17:49:56.565216Z","iopub.execute_input":"2022-12-31T17:49:56.565550Z","iopub.status.idle":"2022-12-31T17:49:56.571073Z","shell.execute_reply.started":"2022-12-31T17:49:56.565517Z","shell.execute_reply":"2022-12-31T17:49:56.569867Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"def trusted_clients(comm_round, historical_preference_dict, f = 3):\n    count_dict = dict()\n    round_pref_list = list(historical_preference_dict[comm_round].values())\n    for pref in round_pref_list:\n        for client in pref:\n            if client not in count_dict:\n                count_dict[client] = 1\n            else:\n                count_dict[client] += 1\n    \n    return dict(filter(lambda elem: elem[1] > f, count_dict.items()))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T18:43:03.729507Z","iopub.execute_input":"2022-12-31T18:43:03.729865Z","iopub.status.idle":"2022-12-31T18:43:03.735513Z","shell.execute_reply.started":"2022-12-31T18:43:03.729831Z","shell.execute_reply":"2022-12-31T18:43:03.734381Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"def trusted_weights_for_round(comm_round, historical_preference_dict, historical_weight_dict, byzantine_clients = [], f = 3):\n    clients = trusted_clients(comm_round, historical_preference_dict, f)\n    \n    selected_byzantine = [x for x in clients if x in byzantine_clients]\n    byzantine_cnt = len(selected_byzantine)\n    \n    if byzantine_cnt > 0:\n        print('Uh oh, byzantines selected', byzantine_cnt)\n    \n    weight_dict = historical_weight_dict[comm_round]\n    return [weight_dict[client] for client in clients]","metadata":{"execution":{"iopub.status.busy":"2022-12-31T19:58:00.087726Z","iopub.execute_input":"2022-12-31T19:58:00.088049Z","iopub.status.idle":"2022-12-31T19:58:00.093451Z","shell.execute_reply.started":"2022-12-31T19:58:00.088019Z","shell.execute_reply":"2022-12-31T19:58:00.092558Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"def multikrum_aggregate(weights, trainers):\n    assert(len(weights) == len(trainers))\n    trainers, scores, weights = score(weights, trainers)\n\n    medians = []\n\n    for t, trainer in enumerate(trainers):\n      medians.append(np.median(scores[t]))\n    print('medians', medians)\n\n    R = len(weights)\n    f = R // 3 - 1\n\n    sorted_idxs = np.argsort(medians)\n    lowest_idxs = sorted_idxs[:R-f]\n    selected_weights = [weights[i] for i in lowest_idxs]\n\n    return fed_avg(selected_weights)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T16:35:23.268052Z","iopub.execute_input":"2022-12-31T16:35:23.268616Z","iopub.status.idle":"2022-12-31T16:35:23.275033Z","shell.execute_reply.started":"2022-12-31T16:35:23.268578Z","shell.execute_reply":"2022-12-31T16:35:23.274103Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"comms_round = 200\nglobal_acc_list = []\nglobal_loss_list = []\nreset_model()    \nhistorical_weight_dict = dict()\nhistorical_preference_dict = dict()\n\n#randomize client data - using keys\nall_client_names = list(clients_batched.keys())\n\nclient_names = random.sample(all_client_names, k=20)\nrandom.shuffle(client_names)\n\nselected_byzantine = [x for x in client_names if x in flipped]\nprint('Byzantine cnt', len(selected_byzantine))","metadata":{"execution":{"iopub.status.busy":"2022-12-31T20:12:01.103573Z","iopub.execute_input":"2022-12-31T20:12:01.103934Z","iopub.status.idle":"2022-12-31T20:12:01.130221Z","shell.execute_reply.started":"2022-12-31T20:12:01.103901Z","shell.execute_reply":"2022-12-31T20:12:01.129376Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"Byzantine cnt 4\n","output_type":"stream"}]},{"cell_type":"code","source":"#commence global training loop\nfor comm_round in range(comms_round):\n    current_weight_dict = dict()\n    historical_preference_dict[comm_round] = dict()\n    # get the global model's weights - will serve as the initial weights for all local models\n    global_weights = global_model.get_weights()\n\n    if debug: \n        # print('all_client_names', all_client_names)\n        print('client_names', client_names)\n    \n    #loop through each client and create new local model\n    for client in client_names:\n        # first do the historical\n        local_preference_calc(comm_round - 1, historical_weight_dict, historical_preference_dict, client)\n        \n        smlp_local = SimpleMLP()\n        local_model = smlp_local.build(build_shape, 10)\n        local_model.compile(loss=loss, \n                      optimizer=optimizer, \n                      metrics=metrics)\n        \n        #set local model weight to the weight of the global model\n        local_model.set_weights(global_weights)\n        \n        #fit local model with client's data\n        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n        \n        current_weight_dict[client] = local_model.get_weights()\n        \n        #clear session to free memory after each communication round\n        K.clear_session()\n        \n    historical_weight_dict[comm_round] = current_weight_dict    \n    # always aggregate the prior round    \n    agg_round = comm_round - 1\n    if agg_round not in historical_weight_dict.keys():\n        continue\n\n        \n#     local_weight_list = list(historical_weight_dict[agg_round].values())\n    local_weight_list = trusted_weights_for_round(agg_round, historical_preference_dict, historical_weight_dict, selected_byzantine, 16)\n    print('No of weights for aggregation', len(local_weight_list))\n    average_weights = fed_avg(local_weight_list)\n#     average_weights = multikrum_aggregate(unscaled_local_weight_list, client_names)\n    \n    #update global model \n    global_model.set_weights(average_weights)\n\n    #test global model and print out metrics after each communications round\n    for(X_test, Y_test) in test_batched:\n        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n        global_acc_list.append(global_acc)\n        global_loss_list.append(global_loss)\n    \n        ","metadata":{"execution":{"iopub.status.busy":"2022-12-31T20:12:06.817054Z","iopub.execute_input":"2022-12-31T20:12:06.817383Z","iopub.status.idle":"2022-12-31T20:39:34.277296Z","shell.execute_reply.started":"2022-12-31T20:12:06.817352Z","shell.execute_reply":"2022-12-31T20:39:34.276041Z"},"trusted":true},"execution_count":129,"outputs":[{"name":"stdout","text":"No of weights for aggregation 6\ncomm_round: 1 | global_acc: 19.738% | global_loss: 2.291950225830078\nNo of weights for aggregation 4\ncomm_round: 2 | global_acc: 21.024% | global_loss: 2.291597843170166\nNo of weights for aggregation 4\ncomm_round: 3 | global_acc: 35.643% | global_loss: 2.278888702392578\nNo of weights for aggregation 7\ncomm_round: 4 | global_acc: 37.810% | global_loss: 2.2783524990081787\nNo of weights for aggregation 6\ncomm_round: 5 | global_acc: 49.857% | global_loss: 2.2631242275238037\nNo of weights for aggregation 6\ncomm_round: 6 | global_acc: 51.357% | global_loss: 2.262322187423706\nNo of weights for aggregation 7\ncomm_round: 7 | global_acc: 58.619% | global_loss: 2.24399471282959\nNo of weights for aggregation 5\ncomm_round: 8 | global_acc: 61.000% | global_loss: 2.243110418319702\nNo of weights for aggregation 7\ncomm_round: 9 | global_acc: 64.786% | global_loss: 2.219609260559082\nNo of weights for aggregation 7\ncomm_round: 10 | global_acc: 66.333% | global_loss: 2.2185561656951904\nNo of weights for aggregation 6\ncomm_round: 11 | global_acc: 69.833% | global_loss: 2.1894023418426514\nNo of weights for aggregation 7\ncomm_round: 12 | global_acc: 69.690% | global_loss: 2.186903715133667\nNo of weights for aggregation 6\ncomm_round: 13 | global_acc: 73.500% | global_loss: 2.153944730758667\nNo of weights for aggregation 7\ncomm_round: 14 | global_acc: 73.143% | global_loss: 2.1504876613616943\nNo of weights for aggregation 6\ncomm_round: 15 | global_acc: 75.024% | global_loss: 2.1132755279541016\nNo of weights for aggregation 7\ncomm_round: 16 | global_acc: 74.690% | global_loss: 2.1101651191711426\nNo of weights for aggregation 6\ncomm_round: 17 | global_acc: 76.452% | global_loss: 2.07444429397583\nNo of weights for aggregation 8\ncomm_round: 18 | global_acc: 76.190% | global_loss: 2.0700125694274902\nNo of weights for aggregation 5\ncomm_round: 19 | global_acc: 77.571% | global_loss: 2.033365488052368\nNo of weights for aggregation 6\ncomm_round: 20 | global_acc: 77.976% | global_loss: 2.032207727432251\nNo of weights for aggregation 6\ncomm_round: 21 | global_acc: 78.143% | global_loss: 1.9974406957626343\nNo of weights for aggregation 8\ncomm_round: 22 | global_acc: 78.667% | global_loss: 1.99349844455719\nNo of weights for aggregation 8\ncomm_round: 23 | global_acc: 79.214% | global_loss: 1.9636874198913574\nNo of weights for aggregation 6\ncomm_round: 24 | global_acc: 79.119% | global_loss: 1.962160348892212\nNo of weights for aggregation 5\ncomm_round: 25 | global_acc: 79.976% | global_loss: 1.9357227087020874\nNo of weights for aggregation 7\ncomm_round: 26 | global_acc: 79.857% | global_loss: 1.931368350982666\nNo of weights for aggregation 7\ncomm_round: 27 | global_acc: 80.214% | global_loss: 1.909328579902649\nNo of weights for aggregation 6\ncomm_round: 28 | global_acc: 80.190% | global_loss: 1.908862590789795\nNo of weights for aggregation 6\ncomm_round: 29 | global_acc: 80.810% | global_loss: 1.8880836963653564\nNo of weights for aggregation 8\ncomm_round: 30 | global_acc: 81.024% | global_loss: 1.8856810331344604\nNo of weights for aggregation 5\ncomm_round: 31 | global_acc: 81.619% | global_loss: 1.8689417839050293\nNo of weights for aggregation 6\ncomm_round: 32 | global_acc: 81.262% | global_loss: 1.8666627407073975\nNo of weights for aggregation 7\ncomm_round: 33 | global_acc: 81.881% | global_loss: 1.851482629776001\nNo of weights for aggregation 8\ncomm_round: 34 | global_acc: 81.786% | global_loss: 1.850836992263794\nNo of weights for aggregation 8\ncomm_round: 35 | global_acc: 82.524% | global_loss: 1.8364133834838867\nNo of weights for aggregation 7\ncomm_round: 36 | global_acc: 82.262% | global_loss: 1.835923433303833\nNo of weights for aggregation 7\ncomm_round: 37 | global_acc: 83.071% | global_loss: 1.8232918977737427\nNo of weights for aggregation 6\ncomm_round: 38 | global_acc: 82.405% | global_loss: 1.8227441310882568\nNo of weights for aggregation 9\ncomm_round: 39 | global_acc: 83.548% | global_loss: 1.810798168182373\nNo of weights for aggregation 7\ncomm_round: 40 | global_acc: 83.167% | global_loss: 1.8104928731918335\nNo of weights for aggregation 8\ncomm_round: 41 | global_acc: 83.881% | global_loss: 1.8003787994384766\nNo of weights for aggregation 6\ncomm_round: 42 | global_acc: 82.810% | global_loss: 1.799492359161377\nNo of weights for aggregation 7\ncomm_round: 43 | global_acc: 84.143% | global_loss: 1.7907720804214478\nNo of weights for aggregation 6\ncomm_round: 44 | global_acc: 83.952% | global_loss: 1.7912077903747559\nNo of weights for aggregation 6\ncomm_round: 45 | global_acc: 84.310% | global_loss: 1.7817034721374512\nNo of weights for aggregation 5\ncomm_round: 46 | global_acc: 83.857% | global_loss: 1.7810750007629395\nNo of weights for aggregation 8\ncomm_round: 47 | global_acc: 84.643% | global_loss: 1.773392915725708\nNo of weights for aggregation 8\ncomm_round: 48 | global_acc: 84.262% | global_loss: 1.772881269454956\nNo of weights for aggregation 7\ncomm_round: 49 | global_acc: 84.571% | global_loss: 1.766862154006958\nNo of weights for aggregation 8\ncomm_round: 50 | global_acc: 84.429% | global_loss: 1.7656891345977783\nNo of weights for aggregation 6\ncomm_round: 51 | global_acc: 84.857% | global_loss: 1.7595278024673462\nNo of weights for aggregation 7\ncomm_round: 52 | global_acc: 84.571% | global_loss: 1.758619785308838\nNo of weights for aggregation 8\ncomm_round: 53 | global_acc: 84.952% | global_loss: 1.754029393196106\nNo of weights for aggregation 7\ncomm_round: 54 | global_acc: 85.048% | global_loss: 1.7521226406097412\nNo of weights for aggregation 7\ncomm_round: 55 | global_acc: 85.357% | global_loss: 1.7474095821380615\nNo of weights for aggregation 7\ncomm_round: 56 | global_acc: 85.143% | global_loss: 1.7467540502548218\nNo of weights for aggregation 8\ncomm_round: 57 | global_acc: 85.643% | global_loss: 1.7416963577270508\nNo of weights for aggregation 8\ncomm_round: 58 | global_acc: 85.262% | global_loss: 1.741188883781433\nNo of weights for aggregation 8\ncomm_round: 59 | global_acc: 85.690% | global_loss: 1.7373136281967163\nNo of weights for aggregation 6\ncomm_round: 60 | global_acc: 85.381% | global_loss: 1.7364475727081299\nNo of weights for aggregation 8\ncomm_round: 61 | global_acc: 85.881% | global_loss: 1.7317326068878174\nNo of weights for aggregation 7\ncomm_round: 62 | global_acc: 85.429% | global_loss: 1.731890082359314\nNo of weights for aggregation 8\ncomm_round: 63 | global_acc: 85.667% | global_loss: 1.7280296087265015\nNo of weights for aggregation 6\ncomm_round: 64 | global_acc: 85.881% | global_loss: 1.7277717590332031\nNo of weights for aggregation 7\ncomm_round: 65 | global_acc: 86.119% | global_loss: 1.7235037088394165\nNo of weights for aggregation 6\ncomm_round: 66 | global_acc: 85.643% | global_loss: 1.7235296964645386\nNo of weights for aggregation 9\ncomm_round: 67 | global_acc: 86.310% | global_loss: 1.71974778175354\nNo of weights for aggregation 7\ncomm_round: 68 | global_acc: 85.881% | global_loss: 1.7202014923095703\nNo of weights for aggregation 7\ncomm_round: 69 | global_acc: 86.333% | global_loss: 1.7162373065948486\nNo of weights for aggregation 6\ncomm_round: 70 | global_acc: 85.929% | global_loss: 1.716088056564331\nNo of weights for aggregation 5\ncomm_round: 71 | global_acc: 86.286% | global_loss: 1.712803840637207\nNo of weights for aggregation 6\ncomm_round: 72 | global_acc: 86.381% | global_loss: 1.7129342555999756\nNo of weights for aggregation 7\ncomm_round: 73 | global_acc: 86.571% | global_loss: 1.7095855474472046\nNo of weights for aggregation 7\ncomm_round: 74 | global_acc: 86.214% | global_loss: 1.7091935873031616\nNo of weights for aggregation 6\ncomm_round: 75 | global_acc: 86.381% | global_loss: 1.7059364318847656\nNo of weights for aggregation 8\ncomm_round: 76 | global_acc: 86.500% | global_loss: 1.7066712379455566\nNo of weights for aggregation 7\ncomm_round: 77 | global_acc: 86.381% | global_loss: 1.7034070491790771\nNo of weights for aggregation 7\ncomm_round: 78 | global_acc: 86.143% | global_loss: 1.7037262916564941\nNo of weights for aggregation 7\ncomm_round: 79 | global_acc: 86.667% | global_loss: 1.7005844116210938\nNo of weights for aggregation 7\ncomm_round: 80 | global_acc: 86.571% | global_loss: 1.7005995512008667\nNo of weights for aggregation 6\ncomm_round: 81 | global_acc: 86.643% | global_loss: 1.6981117725372314\nNo of weights for aggregation 7\ncomm_round: 82 | global_acc: 86.405% | global_loss: 1.6983340978622437\nNo of weights for aggregation 6\ncomm_round: 83 | global_acc: 86.429% | global_loss: 1.6958658695220947\nNo of weights for aggregation 7\ncomm_round: 84 | global_acc: 86.595% | global_loss: 1.6957920789718628\nNo of weights for aggregation 8\ncomm_round: 85 | global_acc: 86.810% | global_loss: 1.6934781074523926\nNo of weights for aggregation 6\ncomm_round: 86 | global_acc: 86.524% | global_loss: 1.693191409111023\nNo of weights for aggregation 7\ncomm_round: 87 | global_acc: 86.476% | global_loss: 1.6912243366241455\nNo of weights for aggregation 8\ncomm_round: 88 | global_acc: 86.619% | global_loss: 1.6911424398422241\nNo of weights for aggregation 7\ncomm_round: 89 | global_acc: 86.762% | global_loss: 1.689581036567688\nNo of weights for aggregation 8\ncomm_round: 90 | global_acc: 86.714% | global_loss: 1.6888996362686157\nNo of weights for aggregation 8\ncomm_round: 91 | global_acc: 86.690% | global_loss: 1.6868964433670044\nNo of weights for aggregation 8\ncomm_round: 92 | global_acc: 86.762% | global_loss: 1.6869549751281738\nNo of weights for aggregation 8\ncomm_round: 93 | global_acc: 86.762% | global_loss: 1.684479832649231\nNo of weights for aggregation 5\ncomm_round: 94 | global_acc: 86.810% | global_loss: 1.6853992938995361\nNo of weights for aggregation 6\ncomm_round: 95 | global_acc: 86.952% | global_loss: 1.6825937032699585\nNo of weights for aggregation 6\ncomm_round: 96 | global_acc: 87.000% | global_loss: 1.6831556558609009\nNo of weights for aggregation 7\ncomm_round: 97 | global_acc: 86.976% | global_loss: 1.680624008178711\nNo of weights for aggregation 7\ncomm_round: 98 | global_acc: 87.000% | global_loss: 1.6811257600784302\nNo of weights for aggregation 8\ncomm_round: 99 | global_acc: 87.095% | global_loss: 1.6791118383407593\nNo of weights for aggregation 6\ncomm_round: 100 | global_acc: 86.952% | global_loss: 1.6802165508270264\nNo of weights for aggregation 7\ncomm_round: 101 | global_acc: 87.095% | global_loss: 1.677522897720337\nNo of weights for aggregation 7\ncomm_round: 102 | global_acc: 87.119% | global_loss: 1.6775715351104736\nNo of weights for aggregation 8\ncomm_round: 103 | global_acc: 87.238% | global_loss: 1.6759569644927979\nNo of weights for aggregation 7\ncomm_round: 104 | global_acc: 87.095% | global_loss: 1.6763097047805786\nNo of weights for aggregation 7\ncomm_round: 105 | global_acc: 87.238% | global_loss: 1.6743146181106567\nNo of weights for aggregation 7\ncomm_round: 106 | global_acc: 87.238% | global_loss: 1.6748727560043335\nNo of weights for aggregation 6\ncomm_round: 107 | global_acc: 87.143% | global_loss: 1.6730774641036987\nNo of weights for aggregation 7\ncomm_round: 108 | global_acc: 87.190% | global_loss: 1.6731966733932495\nNo of weights for aggregation 8\ncomm_round: 109 | global_acc: 87.476% | global_loss: 1.6710875034332275\nNo of weights for aggregation 7\ncomm_round: 110 | global_acc: 87.452% | global_loss: 1.671587586402893\nNo of weights for aggregation 7\ncomm_round: 111 | global_acc: 87.429% | global_loss: 1.6701422929763794\nNo of weights for aggregation 6\ncomm_round: 112 | global_acc: 87.310% | global_loss: 1.670678734779358\nNo of weights for aggregation 7\ncomm_round: 113 | global_acc: 87.452% | global_loss: 1.6687320470809937\nNo of weights for aggregation 8\ncomm_round: 114 | global_acc: 87.310% | global_loss: 1.6688435077667236\nNo of weights for aggregation 7\ncomm_round: 115 | global_acc: 87.500% | global_loss: 1.6674323081970215\nNo of weights for aggregation 7\ncomm_round: 116 | global_acc: 87.310% | global_loss: 1.6682063341140747\nNo of weights for aggregation 5\ncomm_round: 117 | global_acc: 87.500% | global_loss: 1.6666194200515747\nNo of weights for aggregation 7\ncomm_round: 118 | global_acc: 87.500% | global_loss: 1.6665433645248413\nNo of weights for aggregation 8\ncomm_round: 119 | global_acc: 87.452% | global_loss: 1.6649317741394043\nNo of weights for aggregation 6\ncomm_round: 120 | global_acc: 87.381% | global_loss: 1.6654516458511353\nNo of weights for aggregation 6\ncomm_round: 121 | global_acc: 87.619% | global_loss: 1.664176106452942\nNo of weights for aggregation 8\ncomm_round: 122 | global_acc: 87.452% | global_loss: 1.6639692783355713\nNo of weights for aggregation 7\ncomm_round: 123 | global_acc: 87.500% | global_loss: 1.6626014709472656\nNo of weights for aggregation 7\ncomm_round: 124 | global_acc: 87.571% | global_loss: 1.662747859954834\nNo of weights for aggregation 7\ncomm_round: 125 | global_acc: 87.595% | global_loss: 1.6614235639572144\nNo of weights for aggregation 6\ncomm_round: 126 | global_acc: 87.500% | global_loss: 1.662394642829895\nNo of weights for aggregation 7\ncomm_round: 127 | global_acc: 87.690% | global_loss: 1.660341739654541\nNo of weights for aggregation 5\ncomm_round: 128 | global_acc: 87.548% | global_loss: 1.6607071161270142\nNo of weights for aggregation 7\ncomm_round: 129 | global_acc: 87.786% | global_loss: 1.65937340259552\nNo of weights for aggregation 7\ncomm_round: 130 | global_acc: 87.786% | global_loss: 1.660040020942688\nNo of weights for aggregation 7\ncomm_round: 131 | global_acc: 87.810% | global_loss: 1.6584551334381104\nNo of weights for aggregation 6\ncomm_round: 132 | global_acc: 87.810% | global_loss: 1.6585936546325684\nNo of weights for aggregation 8\ncomm_round: 133 | global_acc: 87.738% | global_loss: 1.6572833061218262\nNo of weights for aggregation 8\ncomm_round: 134 | global_acc: 87.762% | global_loss: 1.657593846321106\nNo of weights for aggregation 7\ncomm_round: 135 | global_acc: 87.786% | global_loss: 1.6564680337905884\nNo of weights for aggregation 7\ncomm_round: 136 | global_acc: 87.667% | global_loss: 1.656638503074646\nNo of weights for aggregation 6\ncomm_round: 137 | global_acc: 87.905% | global_loss: 1.655205488204956\nNo of weights for aggregation 6\ncomm_round: 138 | global_acc: 87.833% | global_loss: 1.6564421653747559\nNo of weights for aggregation 9\ncomm_round: 139 | global_acc: 87.976% | global_loss: 1.6544818878173828\nNo of weights for aggregation 7\ncomm_round: 140 | global_acc: 87.762% | global_loss: 1.654778003692627\nNo of weights for aggregation 7\ncomm_round: 141 | global_acc: 87.810% | global_loss: 1.653538703918457\nNo of weights for aggregation 8\ncomm_round: 142 | global_acc: 87.881% | global_loss: 1.6540056467056274\nNo of weights for aggregation 7\ncomm_round: 143 | global_acc: 88.000% | global_loss: 1.6525161266326904\nNo of weights for aggregation 5\ncomm_round: 144 | global_acc: 87.952% | global_loss: 1.6537799835205078\nNo of weights for aggregation 7\ncomm_round: 145 | global_acc: 87.857% | global_loss: 1.6521204710006714\nNo of weights for aggregation 8\ncomm_round: 146 | global_acc: 88.024% | global_loss: 1.6521294116973877\nNo of weights for aggregation 7\ncomm_round: 147 | global_acc: 88.048% | global_loss: 1.651311993598938\nNo of weights for aggregation 5\ncomm_round: 148 | global_acc: 88.119% | global_loss: 1.6513710021972656\nNo of weights for aggregation 7\ncomm_round: 149 | global_acc: 88.095% | global_loss: 1.6504052877426147\nNo of weights for aggregation 7\ncomm_round: 150 | global_acc: 87.976% | global_loss: 1.6506141424179077\nNo of weights for aggregation 6\ncomm_round: 151 | global_acc: 88.190% | global_loss: 1.6493602991104126\nNo of weights for aggregation 7\ncomm_round: 152 | global_acc: 88.262% | global_loss: 1.6498727798461914\nNo of weights for aggregation 7\ncomm_round: 153 | global_acc: 87.929% | global_loss: 1.6492046117782593\nNo of weights for aggregation 6\ncomm_round: 154 | global_acc: 88.119% | global_loss: 1.6496127843856812\nNo of weights for aggregation 6\ncomm_round: 155 | global_acc: 88.238% | global_loss: 1.6479324102401733\nNo of weights for aggregation 7\ncomm_round: 156 | global_acc: 88.238% | global_loss: 1.6487263441085815\nNo of weights for aggregation 7\ncomm_round: 157 | global_acc: 88.262% | global_loss: 1.6473209857940674\nNo of weights for aggregation 8\ncomm_round: 158 | global_acc: 88.167% | global_loss: 1.647857666015625\nNo of weights for aggregation 6\ncomm_round: 159 | global_acc: 88.262% | global_loss: 1.646576166152954\nNo of weights for aggregation 5\ncomm_round: 160 | global_acc: 88.143% | global_loss: 1.6476904153823853\nNo of weights for aggregation 7\ncomm_round: 161 | global_acc: 88.190% | global_loss: 1.646256685256958\nNo of weights for aggregation 6\ncomm_round: 162 | global_acc: 88.238% | global_loss: 1.64656400680542\nNo of weights for aggregation 6\ncomm_round: 163 | global_acc: 88.238% | global_loss: 1.6452299356460571\nNo of weights for aggregation 7\ncomm_round: 164 | global_acc: 88.190% | global_loss: 1.6456489562988281\nNo of weights for aggregation 8\ncomm_round: 165 | global_acc: 88.333% | global_loss: 1.6449425220489502\nNo of weights for aggregation 7\ncomm_round: 166 | global_acc: 88.429% | global_loss: 1.644805908203125\nNo of weights for aggregation 7\ncomm_round: 167 | global_acc: 88.286% | global_loss: 1.6438566446304321\nNo of weights for aggregation 6\ncomm_round: 168 | global_acc: 88.286% | global_loss: 1.6445677280426025\nNo of weights for aggregation 7\ncomm_round: 169 | global_acc: 88.333% | global_loss: 1.643243670463562\nNo of weights for aggregation 7\ncomm_round: 170 | global_acc: 88.429% | global_loss: 1.6435471773147583\nNo of weights for aggregation 7\ncomm_round: 171 | global_acc: 88.381% | global_loss: 1.6426329612731934\nNo of weights for aggregation 6\ncomm_round: 172 | global_acc: 88.571% | global_loss: 1.64323890209198\nNo of weights for aggregation 6\ncomm_round: 173 | global_acc: 88.619% | global_loss: 1.6421962976455688\nNo of weights for aggregation 6\ncomm_round: 174 | global_acc: 88.429% | global_loss: 1.6424267292022705\nNo of weights for aggregation 6\ncomm_round: 175 | global_acc: 88.405% | global_loss: 1.6414484977722168\nNo of weights for aggregation 6\ncomm_round: 176 | global_acc: 88.333% | global_loss: 1.64191734790802\nNo of weights for aggregation 7\ncomm_round: 177 | global_acc: 88.548% | global_loss: 1.6408436298370361\nNo of weights for aggregation 7\ncomm_round: 178 | global_acc: 88.643% | global_loss: 1.6411832571029663\nNo of weights for aggregation 8\ncomm_round: 179 | global_acc: 88.429% | global_loss: 1.640170693397522\nNo of weights for aggregation 6\ncomm_round: 180 | global_acc: 88.452% | global_loss: 1.641049861907959\nNo of weights for aggregation 8\ncomm_round: 181 | global_acc: 88.452% | global_loss: 1.6394951343536377\nNo of weights for aggregation 7\ncomm_round: 182 | global_acc: 88.690% | global_loss: 1.639920949935913\nNo of weights for aggregation 6\ncomm_round: 183 | global_acc: 88.690% | global_loss: 1.639198899269104\nNo of weights for aggregation 6\ncomm_round: 184 | global_acc: 88.452% | global_loss: 1.6395341157913208\nNo of weights for aggregation 7\ncomm_round: 185 | global_acc: 88.476% | global_loss: 1.6386841535568237\nNo of weights for aggregation 6\ncomm_round: 186 | global_acc: 88.500% | global_loss: 1.6389340162277222\nNo of weights for aggregation 7\ncomm_round: 187 | global_acc: 88.500% | global_loss: 1.6382231712341309\nNo of weights for aggregation 7\ncomm_round: 188 | global_acc: 88.667% | global_loss: 1.6382653713226318\nNo of weights for aggregation 7\ncomm_round: 189 | global_acc: 88.738% | global_loss: 1.6374847888946533\nNo of weights for aggregation 6\ncomm_round: 190 | global_acc: 88.619% | global_loss: 1.638045072555542\nNo of weights for aggregation 5\ncomm_round: 191 | global_acc: 88.667% | global_loss: 1.6368422508239746\nNo of weights for aggregation 7\ncomm_round: 192 | global_acc: 88.714% | global_loss: 1.6377688646316528\nNo of weights for aggregation 8\ncomm_round: 193 | global_acc: 88.571% | global_loss: 1.6358952522277832\nNo of weights for aggregation 8\ncomm_round: 194 | global_acc: 88.548% | global_loss: 1.6371073722839355\nNo of weights for aggregation 7\ncomm_round: 195 | global_acc: 88.810% | global_loss: 1.6357306241989136\nNo of weights for aggregation 7\ncomm_round: 196 | global_acc: 88.595% | global_loss: 1.6364725828170776\nNo of weights for aggregation 9\ncomm_round: 197 | global_acc: 88.690% | global_loss: 1.6350843906402588\nNo of weights for aggregation 7\ncomm_round: 198 | global_acc: 88.762% | global_loss: 1.6359376907348633\nNo of weights for aggregation 6\ncomm_round: 199 | global_acc: 88.714% | global_loss: 1.634703278541565\n","output_type":"stream"}]},{"cell_type":"code","source":"# Non-IID \nimport matplotlib.pyplot as plt\nplt.figure(figsize=(16,4))\nplt.subplot(121)\nplt.plot(list(range(0,len(global_loss_list))), global_loss_list)\nplt.subplot(122)\nplt.plot(list(range(0,len(global_acc_list))), global_acc_list)\nprint('Non-IID | total comm rounds', len(global_acc_list))           ","metadata":{"execution":{"iopub.status.busy":"2022-12-31T20:53:09.835088Z","iopub.execute_input":"2022-12-31T20:53:09.835459Z","iopub.status.idle":"2022-12-31T20:53:10.075934Z","shell.execute_reply.started":"2022-12-31T20:53:09.835407Z","shell.execute_reply":"2022-12-31T20:53:10.075031Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"Non-IID | total comm rounds 199\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1152x288 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"noniid_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\nnoniid_df.to_csv('CIFAR-10_Non-IID.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-31T20:53:23.017733Z","iopub.execute_input":"2022-12-31T20:53:23.018072Z","iopub.status.idle":"2022-12-31T20:53:23.163472Z","shell.execute_reply.started":"2022-12-31T20:53:23.018042Z","shell.execute_reply":"2022-12-31T20:53:23.162694Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}